\chapter{Method}
\label{chap:method}

% \thispagestyle{fancy}
% FIXME -- change from cross model to vae-gan

This chapter presents the details and the motivation behind the design choice of the neural network such as the architecture, loss function, optimizers along with the training and evaluation procedure.

\section{Architecture}
To predict root relative 3D pose solely using 2D poses, a hybrid network using \ac{vae} and \ac{gan} as discussed in \ref{subsec:vaeganhybrid} is employed. Each of the components are explained below.

\subsection{Generator - VAE}
In contrast to the \ac{vae}-\ac{gan} hybrid introduced in \cite{autoencoding_beyond_pixels} where only the decoder acts as the generator, both the encoder and the decoder are considered as the generator. In other words the encoder is also updated 

The encoder takes the 2D pose as input and encodes it in a latent space. The decoder samples this encoding using the reparametrization trick and outputs a 3D pose. Following the best practices from \cite{soumith2017wasserstein}, the decoder which is also the generator is made to output 3D poses with values from [-1,1] and Tanh activation is used at the output of the decoder. As described in \ref{chap:data}, the 3D pose is modeled to be of unit length from root to head. However, the lower half of the body could be higher than that. To handle this, the output is multiplied by 2 to cover the true dimensions of the lower half.

% -1 to 1 ...scale to meet the head as 1. logvar instreadof var...

\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/arch/method_arch.png}
    \caption{Illustration of the neural architecture of the proposed method. The network components in blue, encode the 2D pose to a latent representation in terms of mean $\mu$ and variance $\sigma$ of the distribution. While the components in pink, sample $z$ from this latent space and decode the corresponding 3D pose. The 3D pose is projected directly to 2D space for a contrained optimization using input 2D pose in the camera view and randomly rotated and projected for unconstrained optimization using the discriminator $D$ in a novel angle. The data that contributes to the loss function in orange, are mapped with a dotted line.  
    }
    \label{fig:method_arch}
\end{figure}

The encoder consists of an upsampling layer that makes the $2 \cdot j$ dimensional input to match the number of hidden neurons of the encoding module. Where $j$ is the number of joints, here 16. The encoding module is made of $n$ residual block composed of 2 \ac{fc} layers following the related works, to allow comparison. Where $n$ is usually 1 or 2. The enoding block is followed by 2 \ac{fc} layers that downsample the hidden representation to match the latent space dimension. The output of the two downsampling layers represents the mean and variance of the embedding in the latent space. All the layers use \ac{relu} activation unless specified otherwise. The decoder mimics the encoder with an upsampling layer, a decoding module, and a downsampling layer to output 3D pose of dimension $3 \cdot j$.

\subsection{Discriminator}%FIXME -- \subsection{Image \ac{vae}}
The discriminator following the related works also mimics the generator and takes 2D poses as input and predicts binary labels of real or false. The sigmoid activation function is used at the output layer of the discriminator.

\subsection{More on Activation functions}
beta scheduling cycling and o to 1 annealing, weighting the loss components

%FIXME
\subsection{Loss Functions}
beta scheduling cycling and o to 1 annealing, weighting the loss components

\subsection{Optimizers Functions}
beta scheduling cycling and o to 1 annealing, weighting the loss components


\section{Training Scheme}
The training scheme is similar to the standard \ac{vae} and \ac{vae}-\ac{gan} introduced in \ref{sec:Preliminary}. The discriminator is trained first for a few steps before training the \ac{vae}. First, the \ac{vae} takes the 2D pose as input and predicts the 3D pose. This predicted 3D pose is first reprojected to 2D to train the \ac{vae} and then randomly rotated and reprojected to a novel 2D view. This novel 2D is used as fake samples to train the discriminator. As \ac{vae} learns to improve the reprojected 2D pose, it will eventually be very close to the real samples. Using these as the fake examples will not be very useful as the decoder does the same job. Training the discriminator on a randomly rotated and reprojected 2D novel view would encourage the decoder to generate a pose that not only agrees with the input 2D pose but ensures that the other view of the 3D is also indistinguishable from the variations found in the data by fooling the discriminator. This two-view supervision leads to better 3D pose generations.

% \section{Bag of tricks} % TODO -- add tricks to make it work here or at work? -- it should be here
% \lipsum[1-10] %FIXME

\section{Evaluation Metrics} % FIXME
3D \ac{hpe} and Human3.6M in particular is mainly evaluated by \ac{mpjpe} metric. MPJPE as it abbreviates is the mean of the position estimate for all the joints of a pose. Where per-joint position estimate is nothing but the euclidian distance (usually measured in mm) between the predicted joint to its ground truth.


\begin{figure}[h]
    \centering
    \includegraphics[width=\textwidth]{figures/h36_viz/novel_view_contraint.pdf}
    \caption{Illustration of the architecutre and loss flow in the proposed approach.}
    \label{fig:novel_view_constraint}
\end{figure}

% \section{more details the model prints?} % FIXME
