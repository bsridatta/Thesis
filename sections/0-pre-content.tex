\newpage
% \thispagestyle{plain}
% ~\\
% \vfill
% { \setstretch{1.1}
%     \subsection*{Authors}
%     Sri Datta Budaraju <budaraju@kth.se>\\
%     School of Electrical Engineering and Computer Science\\
%     KTH Royal Institute of Technology

%     \subsection*{Place for Project}
%     Stockholm, Sweden\\
%     Stuttgart, Germany

%     \subsection*{Examiner}
%     Danica Kragic Jensfelt\\
%     Stockholm, Sweden\\
%     KTH Royal Institute of Technology

%     \subsection*{Supervisor }
%     Hedvig Kjellström\\
%     Stockholm, Sweden\\
%     KTH Royal Institute of Technology

%     \subsection*{Supervisor - Host}
%     Arij Bouazizi\\
%     Stuttgart, Germany\\
%     Mercedes-Benz AG,  Research and Development
%     ~
% }

% TODO -- uncomment
\newpage
\thispagestyle{plain}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  The English abstract          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Abstract}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The thesis proposes an unsupervised representation learning method to predict 3D human pose from a 2D skeleton via a VAE-GAN (Variational Autoencoder - Generative Adversarial Network) hybrid network. The method learns to lift poses from 2D to 3D using self-supervision and adversarial learning techniques. The method does not use images, heatmaps, 3D pose annotations, paired/unpaired 2D-to-3D skeletons, 3D priors, synthetic 2D skeletons, multi-view or temporal information in any shape or form. The 2D skeleton input is taken by a VAE that encodes it in a latent space and then decodes that latent representation to a 3D pose. The 3D pose is then reprojected to 2D for a constrained, self-supervised optimization using the input 2D pose. Parallelly, the 3D pose is also randomly rotated and reprojected to 2D to generate a 'novel' 2D view for unconstrained adversarial optimization using a discriminator network. The combination of the optimizations of the original and the novel 2D views of the predicted 3D pose results in a 'realistic' 3D pose generation. The thesis shows that the encoding and decoding process of the VAE addresses the major challenge of erroneous and incomplete skeletons from 2D detection networks as inputs and that the variance of the VAE can be altered to get various plausible 3D poses for a given 2D input. Additionally, the latent representation could be used for cross-modal training and many downstream applications. The results on Human3.6M datasets outperform previous unsupervised approaches with less model complexity while addressing more hurdles in scaling the task to the real world.


\subsection*{Keywords}
Computer Vision, Projective Geometry, Deep Learning, Unsupervised Learning, 3D Human Pose Estimation, GAN, AutoEncoder, Hybrid Generative Model, Self-Supervision
% uncomment

% TODO -- uncomment
\newpage
\thispagestyle{plain}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%   The Swedish abstract         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter*{Sammanfattning}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Uppsatsen föreslår en oövervakad metod för representationslärande för att förutsäga en 3D-­pose från ett 2D­-skelett med hjälp av ett VAE­GAN (Variationellt Autoenkodande Generativt Adversariellt Nätverk) hybrid neuralt nätverk. Metoden lär sig att utvidga poser från 2D till 3D genom att använda självövervakning och adversariella inlärningstekniker. Metoden använder sig vare sig av bilder, värmekartor, 3D­-poseannotationer, parade/oparade 2D­-till­-3D skelett, a priori information i 3D, syntetiska 2D-skelett, flera vyer, eller tidsinformation. 2D-skelettindata tas från ett VAE som kodar det i en latent rymd och sedan avkodar den latenta representationen till en 3D-­pose. 3D­-posen är sedan återprojicerad till 2D för att genomgå begränsad, självövervakad optimering med hjälp av den tvådimensionella posen. Parallellt roteras dessutom 3D-­posen slumpmässigt och återprojiceras till 2D för att generera en ny 2D­-vy för obegränsad adversariell optimering med hjälp av ett diskriminatornätverk. Kombinationen av optimeringarna av den ursprungliga och den nya 2D-vyn av den förutsagda 3D-­posen resulterar i en realistisk 3D-posegenerering. Resultaten i uppsatsen visar att kodnings-­ och avkodningsprocessen av VAE adresserar utmaningen med felaktiga och ofullständiga skelett från 2D­-detekteringsnätverk som indata och att variansen av VAE kan modifieras för att få flera troliga 3D­-poser för givna 2D­-indata. Dessutom kan den latenta representationen användas för crossmodal träning och flera nedströmsapplikationer. Resultaten på datamängder från Human3.6M är bättre än tidigare oövervakade metoder med mindre modellkomplexitet samtidigt som de adresserar flera hinder för att skala upp uppgiften till verkliga tillämpningar.
% \subsection*{Nyckelord}
% Computer Vision, Projective Geometry, Deep Learning, Unsupervised Learning, 3D Human Pose Estimation, GAN, AutoEncoder, Hybrid Generative Model, Self-Supervision

\newpage
\thispagestyle{plain}
\chapter*{Acknowledgements}

I would like to express my sincere gratitude to my supervisor at KTH, Hedvig Kjellström, and my industrial supervisor, Arij Bouazizi, for their patient guidance, encouragement, and constructive critique of this research work. I am thankful to my examiner, Danica Kragic Jensfelt, for her feedback and evaluation of this thesis. I am thankful to Mercedes Benz for hosting my thesis and providing me with the required infrastructure. I would also like to express my appreciation to Ulrich Kressel and Julian Wiederer for welcoming me to their research group. I am pleased to acknowledge the helpful feedback, support, and company from my thesis group at KTH and would like to thank Ruibo Tu, Jade Cock, and Oscar Örnberg for their immense help. I am thankful to my friends Nik Vaessen and Vivek Chalumuri for their helpful discussions, comments, and advice throughout the whole process. Finally, I am grateful to my family for their lifelong support. This thesis was carried out during a period of unprecedented uncertainty and was only possible as a result of the incredible patience and empathy shown by everyone involved in the process.

\newpage

\input{sections/0.1-acronyms}

\newpage

\etocdepthtag.toc{mtchapter}
\etocsettagdepth{mtchapter}{subsection}
\etocsettagdepth{mtappendix}{none}
\thispagestyle{plain}
\tableofcontents

\newpage


